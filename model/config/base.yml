vocab:
  char: 'aAàÀảẢãÃáÁạẠăĂằẰẳẲẵẴắẮặẶâÂầẦẩẨẫẪấẤậẬbBcCdDđĐeEèÈẻẺẽẼéÉẹẸêÊềỀểỂễỄếẾệỆfFgGhHiIìÌỉỈĩĨíÍịỊjJkKlLmMnNoOòÒỏỎõÕóÓọỌôÔồỒổỔỗỖốỐộỘơƠờỜởỞỡỠớỚợỢpPqQrRsStTuUùÙủỦũŨúÚụỤưƯừỪửỬữỮứỨựỰvVwWxXyYỳỲỷỶỹỸýÝỵỴzZ0123456789!"#$%&''()*+,-./:;<=>?@[\]^_`{|}~€™ '

device: cpu

trainer:
  batch_size: 32
  print_every: 200
  valid_every: 4000
  iters: 100000
  # where to save our model for prediction
  export: ./weights/transformerocr.pth
  checkpoint: ./checkpoint/transformerocr_checkpoint.pth
  log: ./train.log
  # null to disable compuate accuracy, or change to number of sample to enable validiation while training
  metrics: null

optimizer:
  max_lr: 0.001
  pct_start: 0.1

dataset:    
  # name of your dataset
  name: data
  # path to annotation and image
  data_root: ./img/
  train_annotation: annotation_train.txt
  valid_annotation: annotation_val_small.txt
  # resize image to 32 height, larger height will increase accuracy
  image_height: 32
  image_min_width: 32
  image_max_width: 512

dataloader:
  num_workers: 3
  pin_memory: True

aug:
  image_aug: true
  masked_language_model: true

quiet: False 

backbone:
  
transform:
  encoder_hidden: 256
  decoder_hidden: 256
  img_channel: 256
  decoder_embedded: 256
  dropout: 0.1
  